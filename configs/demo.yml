# A configuration file for demo purpose.
# It contains all setable parameters.


data:
  datasource_name: # source data that the `data_name` derives from
                   # such as the Flickr30K
  datasource_path: # path of the source data

  data_name: # dataset name used in the project, such as 
             # Flickr30K_Entities
  data_path: # path of the dataset

  datasource_download_address: # mainly for google driver 
                            # such as 1mJ-Y0gLFyCLbB6C-M49dUtEsbfVkK4F-
  datasource_download_url:  # mainly for website

  num_workers: # number of workers used to load samples

  is_rgb_resized: # whether resizing the RGB images 
  is_rgb_normalized: # whether normalizing the RGB images

  # set either one of these two
  image_size_scales: # scales when resizing the images
  target_size: # resizing images to the target size 

  # For box types, check
  # https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/
  # for details.
  
  # bounding box of the source dataset
  # [x1, y1, x2, y2]
  src_box_type: # source bounding type 
                # such as, pascal_voc

  # transformed the source bounding box
  # to pascal_voc during the sample
  # transformation
  # vggbase forces the user to utilize the 
  # pascal_voc style bounding boxes.
  # [x1, y1, x2, y2]
  vggbase_work_box_type: # bounding box type that vggbase works on
                        # such as, pascal_voc


environment:

  # do not set this para if the experiments are expected to be placed
  #  in the project_dir directly.
  # Otherwise, they are placed under project_dir/project_name
  project_name: 

  # always utilize the cuda if possible.
  # setting -1 to use the gpu with highest memory
  cuda_device_ids: -1

  # fix the see for reproducible
  seed: 6

  distributed: False # True or False
  distributed_mode: DP # DP or DDP, only DP is supported till now
  global_rank: 0 # this is the global rank
  local_rank: 0 # this is the local rank
  # url used to set up distributed training
  dist_url: tcp://127.0.0.1:3457
  dist_backend: nccl

  # number of distributed processes
  # in general, each gpu performs one process
  world_size: 1

model:
  model_name: # name of the model used by the project 
            # such as LG-DVG

  # whether utilize the pretrained full model,
  # including grounding model and the grounding head
  pretrained: # imagenet
  pretrained_models_dir: # experiments/pretrained_models

  language_module_name: # phrase-bert
  rgb_module_name: # resnet
  grounding_module_name: # LG-DVG
  grounding_header_name: # null

  language_module: # !include ../languages/phrase_bert_module.yml
  rgb_module: # !include ../visuals/resnet101.yml
  grounding_module: # !include ../diffusions/LGDVG_diffusion_proposal200.yml
  grounding_head: # null

  # num_classes
  num_classes: # setting to zero when current vg model does not need classes clf.

  # resume from checkpoint
  #  the name of the checkpoint
  #  or the url used to access the checkpoint
  #  if empty, no loading
  resume: ""


train:

  epochs: # 60
  start_epoch: # 0
  batch_size: # 20

  optimizer: # AdamW
  lr_scheduler: # cosine # options: step, warmupcos

  parameters:
    optimizer:
      # lr: 1.0E-4 # learning rate
      # weight_decay: 1.0E-4

    lr_scheduler:
      # lr_backbone: 1.0E-5
      # lr_drop: 40
      # # warmup learning rate
      # warmup_lr: 1.0E-6

      # # lower lr bound for cyclic schedulers that hit 0 (1e-5)
      # min_lr: 1.0E-7
      # # epochs to warmup LR, if scheduler supports
      # warmup_epochs: 5
      # cooldown_epochs: 5
      # # LR decay rate
      # decay_rate: 0.1
      # lr_noise: 0.001
      # lr_noise_percent: 0.67
      # lr_noise_std: 1.0
      # lr_cycle_limit: 1
      # lr_cycle_mul: 1

  # gradient accumulation step size
  n_iter_grad_acc: # 1

  # gradient clipping max norm
  clip_max_norm: # 0.1

  checkpoint_per_epoch: # 2
  performance_eval_per_epoch: # 1


logging:
  # path where to save, empty for no saving
  experiments_dir: # experiments
  checkpoints_dir: # experiments/checkpoints
  results_dir: # experiments/results

  # number of iteration to print training logs
  tr_log_interval: # 2
  tr_metric_log_interval: # 10
  val_log_interval: # 2
  val_metric_log_interval: # 2

  # visualization dir
  visualizations_dir: # experiments/visualizations

  # visualization frequence
  # int or 0 for no visualization
  tr_visual_interval: # 1
  test_visual_interval: # 1
  val_visual_interval: # 1

  loggings_dir: # experiments/loggings

evaluation:

  # criterion
  criterion_type: # general

  background_label: # 10

  # box format
  box_format: # yolo

  # matcher
  # matcher_type:
  matcher:
    matcher_type: # HunMatcher
    weights:
      # Class coefficient in the matching cost
      cost_class: # 2
      # L1 box coefficient in the matching cost
      cost_bbox_l1: # 5
      # giou box coefficient in the matching cost
      cost_giou: # 2

  # set the losses and the coefficients
  losses:
    weights:
      box:
        l1: # 2
        giou: # 5
    # pseudo_masks:
    #   focal: 2
    #   dice: 1

  # set the hyper parameters for performance
  performance:
    box:
      iou_thresholds_values: Null
      rec_thresholds_values: Null
      max_queries_thresholds: Null
    similarity:
      prob_threshold: 0.5

  # Relative classification weight of the no-object class
  eos_coef: 0.1

  # auxiliary decoding loss
  aux_loss: False

  # iterative box refinement
  with_box_refine: False




